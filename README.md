# AI_DataFlow-Platform
Репозиторий создан в рамках хакатона ЛЦТ2025 для задачи Интеллектуальный цифровой инженер данных

# Инструкция по использованию универсального анализатора данных

Этот документ описывает, как использовать скрипт `universal_data_analyzer.py` для автоматического анализа и получения инсайтов из ваших данных с помощью локальных языковых моделей (LLM) через Ollama.

## 1. Обзор

Скрипт представляет собой инструмент командной строки, который:
1.  **Находит файлы** в указанной директории.
2.  **Автоматически определяет формат** данных (CSV, JSON, XML, Excel, Parquet).
3.  **Надежно считывает данные**, особенно CSV, с автоматическим определением разделителя (`,`, `;`, `\t`, `|`) и кодировки.
4.  **Собирает метаданные** и структурную информацию о файле.
5.  **Формирует промпт** для языковой модели, включающий структуру, статистику и примеры данных.
6.  **Отправляет запрос** в локально запущенную LLM через Ollama.
7.  **Выводит в консоль и сохраняет** детальный отчет в форматах Markdown и JSON, включающий как технический анализ, так и выводы от LLM.

## 2. Требования и установка

### Системные требования
- Python 3.x
- Установленный и запущенный [Ollama](https://ollama.com/) с загруженной моделью (например, `qwen3:30b`).

### Установка зависимостей Python
Скрипт требует несколько Python-библиотек. Установите их с помощью `pip`:

**Обязательные:**
```bash
pip install pandas lxml ollama
```

**Опциональные (рекомендуются для полной функциональности):**
```bash
pip install openpyxl pyarrow rich
```
- `openpyxl`: для работы с файлами Excel (`.xlsx`, `.xls`).
- `pyarrow`: для работы с файлами Parquet.
- `rich`: для красивого и информативного вывода в консоли.

## 3. Подготовка к работе

1.  **Запустите Ollama**: Убедитесь, что сервис Ollama активен и модель, которую вы планируете использовать, загружена. Вы можете загрузить модель командой:
    ```bash
    ollama pull qwen3:30b 
    ```
    *(`qwen3:30b` — модель по умолчанию, вы можете использовать любую другую).*

2.  **Создайте структуру папок**: По умолчанию скрипт ищет файлы в папке `input` и сохраняет результаты в `output`. Создайте их рядом со скриптом:
    ```
    /your_project_folder
    |-- universal_data_analyzer.py  (ваш скрипт)
    |-- input/
    |   `-- my_data.csv
    `-- output/
    ```

3.  **Поместите ваши данные**: Скопируйте файл(ы) для анализа (например, `my_data.csv`) в папку `input`.

## 4. Использование

Скрипт запускается из командной строки. Ниже приведены основные сценарии использования.

### 4.1. Базовый запуск

Для анализа первого найденного файла в папке `input` с использованием модели по умолчанию (`qwen3:30b`), просто запустите скрипт без аргументов:

```bash
python3 universal_data_analyzer.py
```

Скрипт проанализирует файл, выведет краткую сводку и анализ от LLM в консоль, а также создаст два файла с отчетом в папке `output`:
- `my_data_report_YYYYMMDD_HHMMSS.md` (Отчет в формате Markdown)
- `my_data_analysis_YYYYMMDD_HHMMSS.json` (Полные данные анализа в JSON)

### 4.2. Основные аргументы

Вы можете кастомизировать работу скрипта с помощью аргументов командной строки:

| Аргумент              | Сокращение | Описание                                                                  | Пример                                    |
|-----------------------|------------|---------------------------------------------------------------------------|-------------------------------------------|
| `--input-dir`         | `-i`       | Указать папку для поиска данных.                                          | `-i /path/to/data`                        |
| `--output-dir`        | `-o`       | Указать папку для сохранения отчетов.                                     | `-o ./reports`                            |
| `--file-pattern`      | `-f`       | Анализировать конкретный файл (по подстроке в имени).                     | `-f orders_2024.csv`                      |
| `--model`             | `-m`       | Указать имя модели Ollama для анализа.                                    | `-m llama3`                               |
| `--no-save`           |            | Не сохранять результаты в файлы, только выводить в консоль.               | `--no-save`                               |
| `--verbose`           | `-v`       | Включить подробный вывод с диагностикой (попытки чтения, кодировки и т.д.).| `-v`                                      |

**Пример с аргументами:**
```bash
python3 universal_data_analyzer.py -i ./data -o ./results -m llama3 -v
```

### 4.3. Работа с CSV файлами

Скрипт особенно эффективен для анализа "проблемных" CSV файлов.

#### Принудительное указание разделителя
Если автоопределение разделителя работает некорректно, вы можете указать его вручную.

- **Для точки с запятой (`;`):**
  ```bash
  python3 universal_data_analyzer.py --force-separator ";"
  ```
- **Для табуляции (`\t`):** (важно использовать кавычки)
  ```bash
  python3 universal_data_analyzer.py --force-separator "\t"
  ```

#### Помощь в парсинге
Если вы знаете, сколько столбцов должно быть в вашем CSV, это поможет скрипту выбрать наилучший способ парсинга.

```bash
# Если вы ожидаете, что в файле 27 колонок
python3 universal_data_analyzer.py -c 27
```

## 5. Пример вывода

После успешного выполнения в консоли появится отчет, разделенный на блоки:

1.  **КРАТКАЯ СВОДКА**: Основная информация о файле (формат, размер, количество строк и столбцов).
2.  **СТРУКТУРА ДАННЫХ**: Детальная информация о каждом столбце в формате JSON (тип данных, % пропусков, примеры значений).
3.  **АНАЛИЗ LLM**: Развернутый текстовый отчет от языковой модели, который включает:
    - Резюме и бизнес-контекст данных.
    - Оценку качества данных.
    - Найденные аномалии и паттерны.
    - Рекомендации по предобработке, анализу и хранению.
4.  **(В режиме `--verbose`)** **ПОПЫТКИ ЧТЕНИЯ** и **ПРИМЕРЫ ДАННЫХ**: Дополнительная отладочная информация.

Готово! Теперь вы можете использовать этот инструмент для быстрой и глубокой аналитики ваших наборов данных.
